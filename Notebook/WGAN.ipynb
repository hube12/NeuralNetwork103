{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"WGAN.ipynb","provenance":[],"collapsed_sections":["9GYn1dSm5vgz","bHyrLEbV5y9y","tA9hpDVu7OZ7","LCtuJva270pI","nus80uhH73iX"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"ME9DJNDd6FOE","colab_type":"text"},"source":["# Workspace Settings\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"XmQEIT5lAoh7","colab_type":"code","outputId":"6fc24dc7-3ca8-403a-c245-f7bdac9b589c","executionInfo":{"status":"ok","timestamp":1571741115726,"user_tz":-120,"elapsed":3945,"user":{"displayName":"neil","photoUrl":"","userId":"09670409907443135887"}},"colab":{"base_uri":"https://localhost:8080/","height":33}},"source":["%cd /home\n","%rm -rf NeuralNetwork103\n","%ls"],"execution_count":26,"outputs":[{"output_type":"stream","text":["/home\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AECazrey6MOr","colab_type":"code","outputId":"03f50b8a-c8c4-488e-9dc7-016f048bde38","executionInfo":{"status":"ok","timestamp":1571741127146,"user_tz":-120,"elapsed":15355,"user":{"displayName":"neil","photoUrl":"","userId":"09670409907443135887"}},"colab":{"base_uri":"https://localhost:8080/","height":167}},"source":["\n","!git clone https://github.com/hube12/NeuralNetwork103\n","%cd NeuralNetwork103\n","%cd Notebook\n","%rm -rf Results\n","%mkdir Results\n","%ls\n","try:\n","  # %tensorflow_version only exists in Colab.\n","  %tensorflow_version 2.x\n","except Exception:\n","  pass\n","import numpy as np\n","from PIL import Image\n","from math import floor\n","import numpy as np\n","import time\n","from functools import partial\n","from random import random\n","#Imports for layers and models\n","import tensorflow as tf\n","from tensorflow.python.framework.ops import disable_eager_execution\n","disable_eager_execution()\n","from tensorflow.keras.layers import Conv2D, Dense, AveragePooling2D, LeakyReLU, Activation\n","from tensorflow.keras.layers import Reshape, UpSampling2D, Dropout, Flatten, Input, add, Cropping2D\n","from tensorflow.keras.models import model_from_json, Model\n","from tensorflow.keras.optimizers import Adam\n","import tensorflow.keras.backend as K\n","from tensorflow import keras\n","from tensorflow.keras.layers import Layer\n","import matplotlib.pyplot as plt\n","\n","#Config Stuff\n","im_size = 32\n","latent_size = 1024\n","BATCH_SIZE = 16\n","directory = \"Flowers\"\n","n_images = 8189\n","suff = 'jpg'"],"execution_count":27,"outputs":[{"output_type":"stream","text":["Cloning into 'NeuralNetwork103'...\n","remote: Enumerating objects: 48, done.\u001b[K\n","remote: Counting objects: 100% (48/48), done.\u001b[K\n","remote: Compressing objects: 100% (43/43), done.\u001b[K\n","remote: Total 48 (delta 10), reused 15 (delta 1), pack-reused 0\u001b[K\n","Unpacking objects: 100% (48/48), done.\n","/home/NeuralNetwork103\n","/home/NeuralNetwork103/Notebook\n","\u001b[0m\u001b[01;34mModels\u001b[0m/  RBM.ipynb  \u001b[01;34mResults\u001b[0m/  StyleGAN.ipynb  WGAN.ipynb\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9GYn1dSm5vgz","colab_type":"text"},"source":["# Helpers\n"]},{"cell_type":"code","metadata":{"id":"pgOduing5ryQ","colab_type":"code","colab":{}},"source":["class AdaInstanceNormalization(Layer):\n","    def __init__(self, \n","             axis=-1,\n","             momentum=0.99,\n","             epsilon=1e-3,\n","             center=True,\n","             scale=True,\n","             **kwargs):\n","        super(AdaInstanceNormalization, self).__init__(**kwargs)\n","        self.axis = axis\n","        self.momentum = momentum\n","        self.epsilon = epsilon\n","        self.center = center\n","        self.scale = scale\n","    \n","    \n","    def build(self, input_shape):\n","    \n","        dim = input_shape[0][self.axis]\n","        if dim is None:\n","            raise ValueError('Axis ' + str(self.axis) + ' of '\n","                             'input tensor should have a defined dimension '\n","                             'but the layer received an input with shape ' +\n","                             str(input_shape[0]) + '.')\n","    \n","        super(AdaInstanceNormalization, self).build(input_shape) \n","    \n","    def call(self, inputs, training=None):\n","        input_shape = K.int_shape(inputs[0])\n","        reduction_axes = list(range(0, len(input_shape)))\n","        \n","        beta = inputs[1]\n","        gamma = inputs[2]\n","\n","        if self.axis is not None:\n","            del reduction_axes[self.axis]\n","\n","        del reduction_axes[0]\n","        mean = K.mean(inputs[0], reduction_axes, keepdims=True)\n","        stddev = K.std(inputs[0], reduction_axes, keepdims=True) + self.epsilon\n","        normed = (inputs[0] - mean) / stddev\n","\n","        return normed * gamma + beta\n","    \n","    def get_config(self):\n","        config = {\n","            'axis': self.axis,\n","            'momentum': self.momentum,\n","            'epsilon': self.epsilon,\n","            'center': self.center,\n","            'scale': self.scale\n","        }\n","        base_config = super(AdaInstanceNormalization, self).get_config()\n","        return dict(list(base_config.items()) + list(config.items()))\n","    \n","    def compute_output_shape(self, input_shape):\n","    \n","        return input_shape[0]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bHyrLEbV5y9y","colab_type":"text"},"source":["# Code"]},{"cell_type":"markdown","metadata":{"id":"kYuwRwhu7Gkt","colab_type":"text"},"source":["Basics functions\n"]},{"cell_type":"code","metadata":{"id":"50T5GlMD7Ipl","colab_type":"code","colab":{}},"source":["#Style Z\n","def noise(n):\n","    return np.random.normal(0.0, 1.0, size = [n, latent_size])\n","\n","#Noise Sample\n","def noiseImage(n):\n","    return np.random.uniform(0.0, 1.0, size = [n, im_size, im_size, 1])\n","\n","#Get random samples from an array\n","def get_rand(array, amount):\n","    \n","    idx = np.random.randint(0, array.shape[0], amount)\n","    return array[idx]\n","\n","#Import Images Function\n","def import_images(loc, flip = True, suffix = 'png'):\n","    \n","    out = []\n","    cont = True\n","    i = 1\n","    print(\"Importing Images...\")\n","    \n","    while(cont):\n","        try:\n","            temp = Image.open(\"data/\"+loc+\"/im (\"+str(i)+\").\"+suffix+\"\").convert('RGB')\n","            temp = temp.resize((im_size, im_size), Image.BICUBIC)\n","            temp1 = np.array(temp.convert('RGB'), dtype='float32') / 255\n","            out.append(temp1)\n","            if flip:\n","                out.append(np.flip(out[-1], 1))\n","            \n","            i = i + 1\n","        except:\n","            cont = False\n","        \n","    print(str(i-1) + \" images imported.\")\n","            \n","    return np.array(out)\n","\n","def normalize(arr):\n","    return (arr - np.mean(arr)) / (np.std(arr) + 1e-7)\n","\n","#r1/r2 gradient penalty\n","def gradient_penalty_loss(y_true, y_pred,sample_weight, averaged_samples, weight):\n","    gradients = tf.keras.backend.gradients(y_pred, averaged_samples)[0]\n","    gradients_sqr = tf.keras.backend.square(gradients)\n","    gradient_penalty = tf.keras.backend.sum(gradients_sqr,\n","                              axis=np.arange(1, len(gradients_sqr.shape)))\n","    \n","    # weight * ||grad||^2\n","    # Penalize the gradient norm\n","    return tf.keras.backend.mean(gradient_penalty * weight)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tA9hpDVu7OZ7","colab_type":"text"},"source":["# Data picker"]},{"cell_type":"code","metadata":{"id":"RZQa4ivT5efX","colab_type":"code","colab":{}},"source":["#This is the REAL data generator, which can take images from disk and temporarily use them in your program.\n","#Probably could/should get optimized at some point\n","class dataGenerator(object):\n","    \n","    def __init__(self, loc, n, flip = True, suffix = 'png'):\n","        self.loc = \"data/\"+loc\n","        self.flip = flip\n","        self.suffix = suffix\n","        self.n = n\n","    \n","    def get_batch(self, amount):\n","        \n","        idx = np.random.randint(0, self.n - 1, amount) + 1\n","        out = []\n","        \n","        for i in idx:\n","            temp = Image.open(self.loc+\"/im (\"+str(i)+\").\"+self.suffix+\"\").convert('RGB')\n","            temp1 = np.array(temp.convert('RGB'), dtype='float32') / 255\n","            if self.flip and random() > 0.5:\n","                temp1 = np.flip(temp1, 1)\n","                \n","            out.append(temp1)\n","            \n","        \n","        return np.array(out)\n","class dataSet(object):\n","    \n","    def __init__(self, flip = True):\n","        self.flip = flip\n","        (self.im, _), (_, _) = keras.datasets.cifar10.load_data()\n","        self.im = np.float32(self.im) / 255\n","    \n","    def get_batch(self, amount):\n","        \n","        idx = np.random.randint(0, np.shape(self.im)[0] - 1, amount) + 1\n","        out = []\n","        \n","        for i in idx:\n","            temp1 = self.im[i]\n","            if self.flip and random() > 0.5:\n","                temp1 = np.flip(temp1, 1)\n","                \n","            out.append(temp1)\n","            \n","        \n","        return np.array(out)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LCtuJva270pI","colab_type":"text"},"source":["# Generator"]},{"cell_type":"code","metadata":{"id":"eKS5C1rW7kpA","colab_type":"code","colab":{}},"source":["\n","#Upsample, Convolution, AdaIN, Noise, Activation, Convolution, AdaIN, Noise, Activation\n","def g_block(inp, style, noise, fil, u = True):\n","    \n","    b = Dense(fil)(style)\n","    b = Reshape([1, 1, fil])(b)\n","    g = Dense(fil)(style)\n","    g = Reshape([1, 1, fil])(g)\n","\n","    n = Conv2D(filters = fil, kernel_size = 1, padding = 'same', kernel_initializer = 'he_normal')(noise)\n","    \n","    if u:\n","        out = UpSampling2D(interpolation = 'bilinear')(inp)\n","        out = Conv2D(filters = fil, kernel_size = 3, padding = 'same', kernel_initializer = 'he_normal')(out)\n","    else:\n","        out = Activation('linear')(inp)\n","    \n","    out = AdaInstanceNormalization()([out, b, g])\n","    out = add([out, n])\n","    out = LeakyReLU(0.01)(out)\n","    \n","    b = Dense(fil)(style)\n","    b = Reshape([1, 1, fil])(b)\n","    g = Dense(fil)(style)\n","    g = Reshape([1, 1, fil])(g)\n","\n","    n = Conv2D(filters = fil, kernel_size = 1, padding = 'same', kernel_initializer = 'he_normal')(noise)\n","    \n","    out = Conv2D(filters = fil, kernel_size = 3, padding = 'same', kernel_initializer = 'he_normal')(out)\n","    out = AdaInstanceNormalization()([out, b, g])\n","    out = add([out, n])\n","    out = LeakyReLU(0.01)(out)\n","    \n","    return out"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nus80uhH73iX","colab_type":"text"},"source":["# Discriminator"]},{"cell_type":"code","metadata":{"id":"C-AEaZq77mqv","colab_type":"code","colab":{}},"source":["#Convolution, Activation, Pooling, Convolution, Activation\n","def d_block(inp, fil, p = True):\n","    \n","    route2 = Conv2D(filters = fil, kernel_size = 3, padding = 'same', kernel_initializer = 'he_normal')(inp)\n","    route2 = LeakyReLU(0.01)(route2)\n","    if p:\n","        route2 = AveragePooling2D()(route2)\n","    route2 = Conv2D(filters = fil, kernel_size = 3, padding = 'same', kernel_initializer = 'he_normal')(route2)\n","    out = LeakyReLU(0.01)(route2)\n","    \n","    return out"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f_OV2UUD77T-","colab_type":"text"},"source":["# GAN model"]},{"cell_type":"code","metadata":{"id":"s1PRhHni79Ea","colab_type":"code","colab":{}},"source":["#This object holds the models\n","class GAN(object):\n","    \n","    def __init__(self, lr = 0.0001):\n","        \n","        #Models\n","        self.D = None\n","        self.G = None\n","        \n","        self.DM = None\n","        self.AM = None\n","        \n","        #Config\n","        self.LR = lr\n","        self.steps = 1\n","        \n","        #Init Models\n","        self.discriminator()\n","        self.generator()\n","        \n","    def discriminator(self):\n","        \n","        if self.D:\n","            return self.D\n","        \n","        inp = Input(shape = [im_size, im_size, 3])\n","        \n","        # Size\n","        x = d_block(inp, 16) #Size / 2\n","        x = d_block(x, 32) #Size / 4\n","        x = d_block(x, 64) #Size / 8\n","        \n","        if (im_size > 32):\n","            x = d_block(x, 128) #Size / 16\n","        \n","        if (im_size > 64):\n","            x = d_block(x, 192) #Size / 32\n","        \n","        if (im_size > 128):\n","            x = d_block(x, 256) #Size / 64\n","        \n","        if (im_size > 256):\n","            x = d_block(x, 384) #Size / 128\n","            \n","        if (im_size > 512):\n","            x = d_block(x, 512) #Size / 256\n","            \n","            \n","        x = Flatten()(x)\n","        \n","        x = Dense(128)(x)\n","        x = Activation('relu')(x)\n","        \n","        x = Dropout(rate=0.6)(x)\n","        x = Dense(1)(x)\n","        \n","        self.D = Model(inputs = inp, outputs = x)\n","        \n","        return self.D\n","    \n","    def generator(self):\n","        \n","        if self.G:\n","            return self.G\n","        \n","        #Style FC, I only used 2 fully connected layers instead of 8 for faster training\n","        inp_s = Input(shape = [latent_size])\n","        sty = Dense(512, kernel_initializer = 'he_normal')(inp_s)\n","        sty = LeakyReLU(0.1)(sty)\n","        sty = Dense(512, kernel_initializer = 'he_normal')(sty)\n","        sty = LeakyReLU(0.1)(sty)\n","        \n","        #Get the noise image and crop for each size\n","        inp_n = Input(shape = [im_size, im_size, 1])\n","        noi = [Activation('linear')(inp_n)]\n","        curr_size = im_size\n","        while curr_size > 4:\n","            curr_size = int(curr_size / 2)\n","            noi.append(Cropping2D(int(curr_size/2))(noi[-1]))\n","        \n","        #Here do the actual generation stuff\n","        inp = Input(shape = [1])\n","        x = Dense(4 * 4 * 512, kernel_initializer = 'he_normal')(inp)\n","        x = Reshape([4, 4, 512])(x)\n","        x = g_block(x, sty, noi[-1], 512, u=False)\n","        \n","        if(im_size >= 1024):\n","            x = g_block(x, sty, noi[7], 512) # Size / 64\n","        if(im_size >= 512):\n","            x = g_block(x, sty, noi[6], 384) # Size / 64\n","        if(im_size >= 256):\n","            x = g_block(x, sty, noi[5], 256) # Size / 32\n","        if(im_size >= 128):\n","            x = g_block(x, sty, noi[4], 192) # Size / 16\n","        if(im_size >= 64):\n","            x = g_block(x, sty, noi[3], 128) # Size / 8\n","            \n","        x = g_block(x, sty, noi[2], 64) # Size / 4\n","        x = g_block(x, sty, noi[1], 32) # Size / 2\n","        x = g_block(x, sty, noi[0], 16) # Size\n","        \n","        x = Conv2D(filters = 3, kernel_size = 1, padding = 'same', activation = 'sigmoid')(x)\n","        \n","        self.G = Model(inputs = [inp_s, inp_n, inp], outputs = x)\n","        \n","        return self.G\n","    \n","    def AdModel(self):\n","        \n","        #D does not update\n","        self.D.trainable = False\n","        for layer in self.D.layers:\n","            layer.trainable = False\n","        \n","        #G does update\n","        self.G.trainable = True\n","        for layer in self.G.layers:\n","            layer.trainable = True\n","        \n","        #This model is simple sequential one with inputs and outputs\n","        gi = Input(shape = [latent_size])\n","        gi2 = Input(shape = [im_size, im_size, 1])\n","        gi3 = Input(shape = [1])\n","        \n","        gf = self.G([gi, gi2, gi3])\n","        df = self.D(gf)\n","        \n","        self.AM = Model(inputs = [gi, gi2, gi3], outputs = df)\n","            \n","        self.AM.compile(optimizer = Adam(self.LR, beta_1 = 0, beta_2 = 0.99, decay = 0.00001), loss = 'mse')\n","        \n","        return self.AM\n","    \n","    def DisModel(self):\n","        \n","        #D does update\n","        self.D.trainable = True\n","        for layer in self.D.layers:\n","            layer.trainable = True\n","        \n","        #G does not update\n","        self.G.trainable = False\n","        for layer in self.G.layers:\n","            layer.trainable = False\n","        \n","        # Real Pipeline\n","        ri = Input(shape = [im_size, im_size, 3])\n","        dr = self.D(ri)\n","        \n","        # Fake Pipeline\n","        gi = Input(shape = [latent_size])\n","        gi2 = Input(shape = [im_size, im_size, 1])\n","        gi3 = Input(shape = [1])\n","        gf = self.G([gi, gi2, gi3])\n","        df = self.D(gf)\n","        \n","        # Samples for gradient penalty\n","        # For r1 use real samples (ri)\n","        # For r2 use fake samples (gf)\n","        da = self.D(ri)\n","        \n","        # Model With Inputs and Outputs\n","        self.DM = Model(inputs=[ri, gi, gi2, gi3], outputs=[dr, df, da])\n","        \n","        # Create partial of gradient penalty loss\n","        # For r1, averaged_samples = ri\n","        # For r2, averaged_samples = gf\n","        # Weight of 10 typically works\n","        partial_gp_loss = partial(gradient_penalty_loss, averaged_samples = ri, weight = 5)\n","        \n","        #Compile With Corresponding Loss Functions\n","        self.DM.compile(optimizer=Adam(self.LR, beta_1 = 0, beta_2 = 0.99, decay = 0.00001), loss=['mse', 'mse', partial_gp_loss])\n","        \n","        return self.DM\n","   "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Edr2VEOu8NYC","colab_type":"text"},"source":["# WGAN"]},{"cell_type":"code","metadata":{"id":"QLCzOuOv8PsE","colab_type":"code","colab":{}},"source":["class WGAN(object):\n","    \n","    def __init__(self, steps = -1, lr = 0.0001, silent = True, use_dataset=True):\n","        \n","        self.GAN = GAN(lr = lr)\n","        self.DisModel = self.GAN.DisModel()\n","        self.AdModel = self.GAN.AdModel()\n","        self.generator = self.GAN.generator()\n","        \n","        if steps >= 0:\n","            self.GAN.steps = steps\n","        \n","        self.lastblip = time.clock()\n","        \n","        self.noise_level = 0\n","        if use_dataset:\n","          self.im= dataSet(flip=True)\n","        #self.ImagesA = import_images(directory, True)\n","        else:\n","          self.im = dataGenerator(directory, n_images, suffix = suff, flip = True)\n","        \n","        \n","        self.silent = silent\n","\n","        #Train Generator to be in the middle, not all the way at real. Apparently works better??\n","        self.ones = np.ones((BATCH_SIZE, 1), dtype=np.float32)\n","        self.zeros = np.zeros((BATCH_SIZE, 1), dtype=np.float32)\n","        self.nones = -self.ones\n","        \n","        self.enoise = noise(8)\n","        self.enoiseImage = noiseImage(8)\n","    \n","    def train(self):\n","        \n","        #Train Alternating\n","        a = self.train_dis()\n","        b = self.train_gen()\n","        \n","        #Print info\n","        if self.GAN.steps % 20 == 0 and not self.silent:\n","            print(\"\\n\\nRound \" + str(self.GAN.steps) + \":\")\n","            print(\"D: \" + str(a))\n","            print(\"G: \" + str(b))\n","            s = round((time.clock() - self.lastblip) * 1000) / 1000\n","            print(\"T: \" + str(s) + \" sec\")\n","            self.lastblip = time.clock()\n","            \n","            #Save Model\n","            if self.GAN.steps % 500 == 0:\n","                self.save(floor(self.GAN.steps / 10000))\n","            if self.GAN.steps % 1000 == 0:\n","                self.evaluate(floor(self.GAN.steps / 1000))\n","            \n","        \n","        self.GAN.steps = self.GAN.steps + 1\n","          \n","    def train_dis(self):\n","        \n","        #Get Data\n","        train_data = [self.im.get_batch(BATCH_SIZE), noise(BATCH_SIZE), noiseImage(BATCH_SIZE), self.ones]\n","        \n","        #Train\n","        d_loss = self.DisModel.train_on_batch(train_data, [self.ones, self.nones, self.ones])\n","        \n","        return d_loss\n","       \n","    def train_gen(self):\n","        \n","        #Train\n","        g_loss = self.AdModel.train_on_batch([noise(BATCH_SIZE), noiseImage(BATCH_SIZE), self.ones], self.zeros)\n","        \n","        return g_loss\n","    \n","    def evaluate(self, num = 0, trunc = 2.0): #8x4 images, bottom row is constant\n","        \n","        n = noise(32)\n","        n2 = noiseImage(32)\n","        \n","        im2 = self.generator.predict([n, n2, np.ones([32, 1])])\n","        im3 = self.generator.predict([self.enoise, self.enoiseImage, np.ones([8, 1])])\n","        \n","        r12 = np.concatenate(im2[:8], axis = 1)\n","        r22 = np.concatenate(im2[8:16], axis = 1)\n","        r32 = np.concatenate(im2[16:24], axis = 1)\n","        r43 = np.concatenate(im3[:8], axis = 1)\n","        \n","        c1 = np.concatenate([r12, r22, r32, r43], axis = 0)\n","        \n","        x = Image.fromarray(np.uint8(c1*255))\n","        \n","        x.save(\"Results/i\"+str(num)+\".jpg\")\n","        \n","    def evaluate2(self, s1, s2, n1, n2, num = 0, weight = 0.5):\n","        \n","        s = normalize((s2 * weight) + (s1 * (1 - weight)))\n","        n = (n2 * weight) + (n1 * (1 - weight))\n","        \n","        im2 = self.generator.predict([s, n, np.ones([32, 1])])\n","        \n","        r12 = np.concatenate(im2[:8], axis = 1)\n","        r22 = np.concatenate(im2[8:16], axis = 1)\n","        r32 = np.concatenate(im2[16:24], axis = 1)\n","        r43 = np.concatenate(im2[24:], axis = 1)\n","        \n","        c1 = np.concatenate([r12, r22, r32, r43], axis = 0)\n","        \n","        x = Image.fromarray(np.uint8(c1*255))\n","        \n","        x.save(\"Results/i\"+str(num)+\".jpg\")\n","        \n","    def evalTrunc(self, num = 0, trunc = 1.8):\n","        \n","        n = np.clip(noise(16), -trunc, trunc)\n","        n2 = noiseImage(16)\n","        \n","        im2 = self.generator.predict([n, n2, np.ones([16, 1])])\n","        \n","        r12 = np.concatenate(im2[:4], axis = 1)\n","        r22 = np.concatenate(im2[4:8], axis = 1)\n","        r32 = np.concatenate(im2[8:12], axis = 1)\n","        r43 = np.concatenate(im2[12:], axis = 1)\n","        \n","        c1 = np.concatenate([r12, r22, r32, r43], axis = 0)\n","        \n","        x = Image.fromarray(np.uint8(c1*255))\n","        \n","        x.save(\"Results/t\"+str(num)+\".jpg\")\n","        \n","    \n","    def saveModel(self, model, name, num): #Save a Model\n","        json = model.to_json()\n","        with open(\"Models/\"+name+\".json\", \"w\") as json_file:\n","            json_file.write(json)\n","            \n","        model.save_weights(\"Models/\"+name+\"_\"+str(num)+\".h5\")\n","        \n","    def loadModel(self, name, num): #Load a Model\n","        \n","        file = open(\"Models/\"+name+\".json\", 'r')\n","        json = file.read()\n","        file.close()\n","        \n","        mod = model_from_json(json, custom_objects = {'AdaInstanceNormalization': AdaInstanceNormalization})\n","        mod.load_weights(\"Models/\"+name+\"_\"+str(num)+\".h5\")\n","        \n","        return mod\n","    \n","    def save(self, num): #Save JSON and Weights into /Models/\n","        self.saveModel(self.GAN.G, \"gen\", num)\n","        self.saveModel(self.GAN.D, \"dis\", num)\n","        \n","\n","    def load(self, num): #Load JSON and Weights from /Models/\n","        steps1 = self.GAN.steps\n","        \n","        self.GAN = None\n","        self.GAN = GAN()\n","\n","        #Load Models\n","        self.GAN.G = self.loadModel(\"gen\", num)\n","        self.GAN.D = self.loadModel(\"dis\", num)\n","        \n","        self.GAN.steps = steps1\n","        \n","        self.generator = self.GAN.generator()\n","        self.DisModel = self.GAN.DisModel()\n","        self.AdModel = self.GAN.AdModel()\n","        \n"," "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iIaxaQLy8R33","colab_type":"text"},"source":["# Run"]},{"cell_type":"code","metadata":{"id":"VVSOlsffIAzb","colab_type":"code","colab":{}},"source":["def visualize(num=0):\n","  temp = Image.open(\"Results/i\"+str(num)+\".jpg\")\n","  print(np.shape(temp))\n","  plt.imshow(temp)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4BcZ2_-Q8UpS","colab_type":"code","outputId":"1cd35b6f-8eca-43ec-e8f2-0b179488b8d3","executionInfo":{"status":"error","timestamp":1571741227189,"user_tz":-120,"elapsed":115263,"user":{"displayName":"neil","photoUrl":"","userId":"09670409907443135887"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["if __name__ == \"__main__\":\n","    model = WGAN(lr = 0.0003, silent = False)\n","  \n","    for j in range(100):\n","      for i in range (60):\n","        model.train()\n","      model.save(j)   \n","      %ls Models   \n"],"execution_count":36,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n","\n","\n","Round 20:\n","D: [2.1464655, 1.109251, 0.8872255, 0.14998896]\n","G: 0.21920437\n","T: 20.303 sec\n","\n","\n","Round 40:\n","D: [1.5000669, 0.47293088, 0.83180153, 0.1953344]\n","G: 0.120810404\n","T: 2.605 sec\n","\n","\n","Round 60:\n","D: [0.8625921, 0.256293, 0.3554607, 0.2508384]\n","G: 0.45582825\n","T: 2.639 sec\n","dis_0.h5  dis_99.h5  dis.json  gen_0.h5  gen_99.h5  gen.json\n","\n","\n","Round 80:\n","D: [0.3987533, 0.14201486, 0.15421274, 0.10252568]\n","G: 0.5850842\n","T: 26.242 sec\n","\n","\n","Round 100:\n","D: [1.7020808, 0.4026931, 1.2205126, 0.07887521]\n","G: 0.010466894\n","T: 2.611 sec\n","\n","\n","Round 120:\n","D: [1.945781, 1.5287952, 0.08812778, 0.32885808]\n","G: 0.13397855\n","T: 2.623 sec\n","dis_0.h5  dis_99.h5  gen_0.h5  gen_99.h5\n","dis_1.h5  dis.json   gen_1.h5  gen.json\n","\n","\n","Round 140:\n","D: [1.6574736, 0.8507209, 0.6295885, 0.17716426]\n","G: 0.015709559\n","T: 2.829 sec\n","\n","\n","Round 160:\n","D: [2.6520948, 0.21018541, 2.2797213, 0.16218817]\n","G: 0.017381452\n","T: 2.558 sec\n","\n","\n","Round 180:\n","D: [2.111406, 1.195864, 0.50800264, 0.40753943]\n","G: 0.089984246\n","T: 2.57 sec\n","dis_0.h5  dis_2.h5   dis.json  gen_1.h5  gen_99.h5\n","dis_1.h5  dis_99.h5  gen_0.h5  gen_2.h5  gen.json\n","\n","\n","Round 200:\n","D: [1.856379, 0.89173067, 0.6140458, 0.35060263]\n","G: 0.034128018\n","T: 2.874 sec\n","\n","\n","Round 220:\n","D: [1.8621242, 0.8673922, 0.7755122, 0.21921983]\n","G: 0.38411158\n","T: 2.551 sec\n","\n","\n","Round 240:\n","D: [2.2459376, 1.3827872, 0.596737, 0.2664134]\n","G: 0.021089293\n","T: 2.628 sec\n","dis_0.h5  dis_2.h5  dis_99.h5  gen_0.h5  gen_2.h5  gen_99.h5\n","dis_1.h5  dis_3.h5  dis.json   gen_1.h5  gen_3.h5  gen.json\n","\n","\n","Round 260:\n","D: [1.9841244, 1.2828962, 0.4621248, 0.23910345]\n","G: 0.04638888\n","T: 2.886 sec\n","\n","\n","Round 280:\n","D: [1.7036732, 0.8374405, 0.7031971, 0.1630356]\n","G: 0.04802007\n","T: 2.617 sec\n","\n","\n","Round 300:\n","D: [1.6996446, 0.42721668, 1.0947199, 0.17770806]\n","G: 0.06357892\n","T: 2.613 sec\n","dis_0.h5  dis_2.h5  dis_4.h5   dis.json  gen_1.h5  gen_3.h5  gen_99.h5\n","dis_1.h5  dis_3.h5  dis_99.h5  gen_0.h5  gen_2.h5  gen_4.h5  gen.json\n","\n","\n","Round 320:\n","D: [1.939345, 0.98159605, 0.7574346, 0.20031437]\n","G: 0.04866651\n","T: 2.807 sec\n","\n","\n","Round 340:\n","D: [1.9232686, 0.80765426, 0.9082011, 0.20741321]\n","G: 0.08454247\n","T: 2.581 sec\n","\n","\n","Round 360:\n","D: [1.9541972, 0.7690254, 0.98523694, 0.19993487]\n","G: 0.05444365\n","T: 2.586 sec\n","dis_0.h5  dis_3.h5  dis_99.h5  gen_1.h5  gen_4.h5   gen.json\n","dis_1.h5  dis_4.h5  dis.json   gen_2.h5  gen_5.h5\n","dis_2.h5  dis_5.h5  gen_0.h5   gen_3.h5  gen_99.h5\n","\n","\n","Round 380:\n","D: [2.1091459, 1.2596745, 0.64418614, 0.20528528]\n","G: 0.05341798\n","T: 2.809 sec\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-36-17c8e27a0bc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m       \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ls Models'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-34-c2176176d48e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m#Train Alternating\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m#Print info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-34-c2176176d48e>\u001b[0m in \u001b[0;36mtrain_gen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;31m#Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoiseImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mg_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    990\u001b[0m     x, y, sample_weights = self._standardize_user_data(\n\u001b[1;32m    991\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 992\u001b[0;31m         extract_tensors_from_dataset=True)\n\u001b[0m\u001b[1;32m    993\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m     \u001b[0;31m# If `self._distribution_strategy` is True, then we are in a replica context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2447\u001b[0m     \u001b[0;31m# in the case where all inputs are value arrays.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2449\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2450\u001b[0m       \u001b[0;31m# In eager mode, do not do shape validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2451\u001b[0m       \u001b[0;31m# since the network has no input nodes (placeholders) to be fed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mrun_eagerly\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    452\u001b[0m       raise ValueError('You can only set `run_eagerly=True` if eager execution '\n\u001b[1;32m    453\u001b[0m                        'is enabled.')\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_eagerly\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0;31m# Respect `tf.config.experimental_run_functions_eagerly` unless\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36mdynamic\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    388\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mdynamic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_graph_network\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamic\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    388\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mdynamic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_graph_network\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamic\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36mdynamic\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    388\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mdynamic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_graph_network\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamic\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36mlayers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    504\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m     return trackable_layer_utils.filter_empty_layer_containers(\n\u001b[0;32m--> 506\u001b[0;31m         self._layers)\n\u001b[0m\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/training/tracking/layer_utils.py\u001b[0m in \u001b[0;36mfilter_empty_layer_containers\u001b[0;34m(layer_list)\u001b[0m\n\u001b[1;32m     48\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0mto_visit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_visit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexisting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mexisting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/util/object_identity.py\u001b[0m in \u001b[0;36m__contains__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__contains__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mdiscard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-2.0.0/python3.6/tensorflow_core/python/util/object_identity.py\u001b[0m in \u001b[0;36m__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;31m# id(weakref.ref(a)) == id(weakref.ref(a)) and weakref.ref(a) is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;31m# weakref.ref(a) in _WeakObjectIdentityWrapper.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"mF-eKZdEJX1F","colab_type":"code","colab":{}},"source":["from google.colab import files\n","#files.download(\"Models/dis_99.h5\")\n","#files.download(\"Models/gen_99.h5\")\n","model.evaluate()\n","visualize()"],"execution_count":0,"outputs":[]}]}